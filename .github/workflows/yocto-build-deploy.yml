name: "Yocto"

on:
  workflow_call:
    secrets:
      BALENA_API_KEY:
        description: balena API key for deploying releases # TODO: Different for staging and prod - add another Secret for staging key
        required: false
      DOCKERHUB_USER:
        description: Dockerhub user for pulling private helper images
        required: false
      DOCKERHUB_TOKEN:
        description: Dockerhub token for pulling private helper images
        required: false
      SIGN_KMOD_KEY_APPEND:
        description: Base64-encoded public key of a kernel module signing keypair
        required: false
      # TODO: can this be the same as BALENA_API_KEY?
      SIGN_API_KEY:
        description: balena API key that provides access to the signing server
        required: false
    inputs:
      runs-on:
        description: The runner labels to use for the job(s)
        required: false
        type: string
        default: >
          [
            "self-hosted",
            "X64"
          ]
      device-repo:
        description: balenaOS device repository (owner/repo)
        required: false
        type: string
        default: ${{ github.repository }}
      device-repo-ref:
        description: balenaOS device repository tag, branch, or commit to build
        required: false
        type: string
        default: ${{ github.ref }}
      meta-balena-ref:
        description: meta-balena ref if not the currently pinned version
        required: false
        type: string
      yocto-scripts-ref:
        description: balena-yocto-scripts ref if not the currently pinned version
        required: false
        type: string
      machine:
        description: yocto board name
        required: true
        type: string
      environment:
        description: The GitHub Environment to use for the job(s) (production, staging, etc.)
        required: false
        type: string
        default: staging
      deploy-s3:
        description: Whether to deploy images to S3
        required: false
        type: boolean
        default: true
      deploy-hostapp:
        description: Whether to deploy a hostApp container image to a balena environment
        required: false
        type: boolean
        default: true
      deploy-ami:
        description: Whether to deploy an AMI to AWS
        required: false
        type: boolean
        default: false
      sign-image:
        description: Whether to sign image for secure boot
        required: false
        type: boolean
        default: false
      os-dev:
        description: Enable OS development features
        required: false
        type: boolean
        default: false
      deploy-esr:
        description: Enable to deploy ESR
        required: false
        type: boolean
        default: false
      aws_iam_role:
        description: IAM role to assume for s3 permissions
        required: false
        type: string
        default: "arn:aws:iam::567579488761:role/balena-os-deploy-s3-access-Role-8r0SXqfzgolr" #TODO - Replace using environments
      aws_region:
        description: AWS region
        required: false
        type: string
        default: "us-east-1"

# https://docs.github.com/en/actions/using-jobs/using-concurrency
concurrency:
  group: ${{ github.workflow }}-${{ github.event.number || github.ref }}-${{ inputs.machine }}
  # cancel jobs in progress for updated PRs, but not merge or tag events
  cancel-in-progress: ${{ github.event.action == 'synchronize' }}

env:
  WORKSPACE: ${{ github.workspace }}
  MACHINE: ${{ inputs.machine }}
  VERBOSE: verbose

permissions:
  id-token: write   # This is required for requesting the JWT #https://docs.github.com/en/actions/deployment/security-hardening-your-deployments/configuring-openid-connect-in-amazon-web-services#requesting-the-access-token

jobs:
  build:
    name: Build
    runs-on: ${{ fromJSON(inputs.runs-on) }}
    environment: ${{ inputs.environment }}

    env:
      automation_dir: "${{ github.workspace }}/balena-yocto-scripts/automation"
      BALENARC_BALENA_URL: ${{ vars.BALENA_URL || 'balena-cloud.com' }}
      API_ENV: ${{ vars.BALENA_URL || 'balena-cloud.com' }}

      # Yocto NFS sstate cache host
      YOCTO_CACHE_HOST: ${{ vars.YOCTO_CACHE_HOST || 'nfs.product-os.io' }}
      YOCTO_CACHE_DIR: ${{ github.workspace }}/shared/yocto-cache
      # S3_CACHE_URL: s3://balena-yocto-cache/${{ inputs.machine }}
      BARYS_ARGUMENTS_VAR: ""

      # URL for secure boot signing server API
      SIGN_API_URL: ${{ vars.SIGN_API_URL || 'https://sign.balena-cloud.com' }}

      # used for deploying images to S3 and deploying AMIs to AWS
      S3_REGION: ${{ vars.S3_REGION || 'us-east-1' }}
      S3_BUCKET: ${{ vars.AWS_S3_BUCKET || vars.S3_BUCKET }}

    outputs:
      os_version: ${{ steps.balena-lib.outputs.os_version }}
      device_slug: ${{ steps.balena-lib.outputs.device_slug }}
      deploy_artifact: ${{ steps.balena-lib.outputs.deploy_artifact }}
      is_private: ${{ steps.balena-lib.outputs.is_private }}
      dt_arch: ${{ steps.balena-lib.outputs.dt_arch }}
      meta_balena_version: ${{ steps.balena-lib.outputs.meta_balena_version }}
      yocto_scripts_ref: ${{ steps.balena-lib.outputs.yocto_scripts_ref }}
      yocto_scripts_version: ${{ steps.balena-lib.outputs.yocto_scripts_version }}

    defaults:
      run:
        working-directory: .
        shell: bash --noprofile --norc -eo pipefail -x {0}

    steps:
      # https://github.com/product-os/flowzone/blob/d92a0f707ca791ea4432306fcb35008848cc9bcb/flowzone.yml#L449-L473
      - name: Reject unapproved external contributions
        env:
          ok_to_test_label: ok-to-test
          # https://cli.github.com/manual/gh_help_environment
          GH_DEBUG: "true"
          GH_PAGER: "cat"
          GH_PROMPT_DISABLED: "true"
          GH_REPO: "${{ inputs.device-repo }}"
          GH_TOKEN: "${{ secrets.GITHUB_TOKEN }}"
        if: |
          github.event.pull_request.state == 'open' &&
          github.event.pull_request.head.repo.full_name != github.repository
        run: |
          pr_labels="$(gh pr view ${{ github.event.pull_request.number }} --json labels -q .labels[].name)"

          for label in "${pr_labels}"
          do
            if [[ "$label" =~ "${{ env.ok_to_test_label }}" ]]
            then
              gh pr edit ${{ github.event.pull_request.number }} --remove-label "${{ env.ok_to_test_label }}"
              exit 0
            fi
          done

          echo "::error::External contributions must be approved with the label '${{ env.ok_to_test_label }}'. \
            Please contact a member of the organization for assistance."
          exit 1

      # this must be done before putting files in the workspace
      # https://github.com/easimon/maximize-build-space
      - name: Maximize build space
        if: contains(fromJSON(inputs.runs-on), 'self-hosted') == false
        uses: easimon/maximize-build-space@fc881a613ad2a34aca9c9624518214ebc21dfc0c
        with:
          root-reserve-mb: "4096"
          temp-reserve-mb: "1024"
          swap-size-mb: "4096"
          remove-dotnet: "true"
          remove-android: "true"
          remove-haskell: "true"
          remove-codeql: "true"
          remove-docker-images: "true"

      # https://github.com/actions/checkout
      - name: Clone device repository
        uses: actions/checkout@v4.1.1
        with:
          repository: ${{ inputs.device-repo }}
          token: ${{ secrets.GITHUB_TOKEN }}
          ref: ${{ inputs.device-repo-ref }}
          submodules: true
          # fetch-depth: 1 
          fetch-tags: true

      - name: Device repository check
        run: |
          if [ "$(yq '.type' repo.yml)" != "yocto-based OS image" ]; then
            echo "::error::Repository does not appear to be of type 'yocto-based OS image'"
            exit 1
          fi

      - name: Update meta-balena submodule to ${{ inputs.meta-balena-ref }}
        if: inputs.meta-balena-ref != ''
        working-directory: ./layers/meta-balena
        run: |
          git config --add remote.origin.fetch '+refs/pull/*:refs/remotes/origin/pr/*'
          git fetch --all
          git checkout --force "${{ inputs.meta-balena-ref }}"
          git submodule update --init --recursive

      - name: Update balena-yocto-scripts submodule to ${{ inputs.yocto-scripts-ref }}
        if: inputs.yocto-scripts-ref != ''
        working-directory: ./balena-yocto-scripts
        run: |
          git config --add remote.origin.fetch '+refs/pull/*:refs/remotes/origin/pr/*'
          git fetch --all
          git checkout --force "${{ inputs.yocto-scripts-ref }}"
          git submodule update --init --recursive

      - name: Set build outputs
        id: balena-lib
        run: |
          source "${automation_dir}/include/balena-api.inc"
          source "${automation_dir}/include/balena-lib.inc"

          ./balena-yocto-scripts/build/build-device-type-json.sh

          device_slug="$(balena_lib_get_slug "${MACHINE}")"
          echo "device_slug=${device_slug}" >> $GITHUB_OUTPUT

          os_version=$(git describe --abbrev=0)
          echo "os_version=${os_version#v*}" >> $GITHUB_OUTPUT

          # os_version="$(balena_lib_get_os_version)"
          # echo "os_version=${os_version}" >> $GITHUB_OUTPUT

          meta_balena_version="$(balena_lib_get_meta_balena_base_version)"
          echo "meta_balena_version=${meta_balena_version}" >> $GITHUB_OUTPUT

          yocto_scripts_ref="$(git submodule status balena-yocto-scripts | awk '{print $1}')"
          echo "yocto_scripts_ref=${yocto_scripts_ref}" >> $GITHUB_OUTPUT

          yocto_scripts_version="$(cd balena-yocto-scripts && head -n1 VERSION)"
          echo "yocto_scripts_version=${yocto_scripts_version}" >> $GITHUB_OUTPUT

          deploy_artifact="$(balena_lib_get_deploy_artifact "${MACHINE}")"
          echo "deploy_artifact=${deploy_artifact}" >> $GITHUB_OUTPUT

          dt_arch="$(balena_lib_get_dt_arch "${MACHINE}")"
          echo "dt_arch=${dt_arch}" >> $GITHUB_OUTPUT

          is_private="$(balena_api_is_dt_private "${{ inputs.machine }}")"
          echo "is_private=${is_private}" >> $GITHUB_OUTPUT

          if [ ! -f "${WORKSPACE}/balena.yml" ]; then
            _contract=$(balena_lib_build_contract "${device_slug}")
            cp "${_contract}" "${WORKSPACE}/balena.yml"
          fi

      - name: Enable OS development features
        if: inputs.os-dev == true
        run: |
          if [ "${OS_DEVELOPMENT}" = "true" ]; then
            echo BARYS_ARGUMENTS_VAR="${BARYS_ARGUMENTS_VAR} -d" >> $GITHUB_ENV
          fi

      # https://docs.yoctoproject.org/dev/dev-manual/speeding-up-build.html#speeding-up-a-build
      - name: Configure bitbake resource limits
        env:
          BB_NUMBER_THREADS: 4
          BB_NUMBER_PARSE_THREADS: 4
          PARALLEL_MAKE: -j4
          PARALLEL_MAKEINST: -j4
          BB_PRESSURE_MAX_CPU: 500
          BB_PRESSURE_MAX_IO: 500
          BB_PRESSURE_MAX_MEMORY: 500
        run: |
          nproc
          free -h
          BARYS_ARGUMENTS_VAR="${BARYS_ARGUMENTS_VAR} -a BB_NUMBER_THREADS=${BB_NUMBER_THREADS}"
          BARYS_ARGUMENTS_VAR="${BARYS_ARGUMENTS_VAR} -a BB_NUMBER_PARSE_THREADS=${BB_NUMBER_PARSE_THREADS}"
          BARYS_ARGUMENTS_VAR="${BARYS_ARGUMENTS_VAR} -a PARALLEL_MAKE=${PARALLEL_MAKE}"
          BARYS_ARGUMENTS_VAR="${BARYS_ARGUMENTS_VAR} -a PARALLEL_MAKEINST=${PARALLEL_MAKEINST}"
          BARYS_ARGUMENTS_VAR="${BARYS_ARGUMENTS_VAR} -a BB_PRESSURE_MAX_CPU=${BB_PRESSURE_MAX_CPU}"
          BARYS_ARGUMENTS_VAR="${BARYS_ARGUMENTS_VAR} -a BB_PRESSURE_MAX_IO=${BB_PRESSURE_MAX_IO}"
          BARYS_ARGUMENTS_VAR="${BARYS_ARGUMENTS_VAR} -a BB_PRESSURE_MAX_MEMORY=${BB_PRESSURE_MAX_MEMORY}"
          echo "BARYS_ARGUMENTS_VAR=${BARYS_ARGUMENTS_VAR}" >> $GITHUB_ENV

      - name: Enable signed images
        if: inputs.sign-image == true
        env:
          SIGN_API_KEY: "${{ secrets.SIGN_API_KEY }}"
          SIGN_GRUB_KEY_ID: 2EB29B4CE0132F6337897F5FB8A88D1C62FCC729
          SIGN_KMOD_KEY_APPEND: "${{ secrets.SIGN_KMOD_KEY_APPEND }}"
        run: |
          BARYS_ARGUMENTS_VAR="${BARYS_ARGUMENTS_VAR} -a SIGN_API=${SIGN_API_URL}"
          BARYS_ARGUMENTS_VAR="${BARYS_ARGUMENTS_VAR} -a SIGN_API_KEY=${SIGN_API_KEY}"
          BARYS_ARGUMENTS_VAR="${BARYS_ARGUMENTS_VAR} -a SIGN_GRUB_KEY_ID=${SIGN_GRUB_KEY_ID}"
          BARYS_ARGUMENTS_VAR="${BARYS_ARGUMENTS_VAR} -a SIGN_KMOD_KEY_APPEND=${SIGN_KMOD_KEY_APPEND}"
          BARYS_ARGUMENTS_VAR="${BARYS_ARGUMENTS_VAR} --bb-args --no-setscene"
          echo "BARYS_ARGUMENTS_VAR=${BARYS_ARGUMENTS_VAR}" >> $GITHUB_ENV

      # the directory is required even if we don't mount the NFS share
      - name: Create shared cache mount point
        run: |
          sudo mkdir -p "${YOCTO_CACHE_DIR}/$(whoami)"
          sudo chown -R $(id -u):$(id -g) "${YOCTO_CACHE_DIR}"

      - name: Mount shared NFS cache
        if: env.YOCTO_CACHE_HOST != '' && contains(fromJSON(inputs.runs-on), 'self-hosted')
        run: |
          sudo mount -t nfs "${YOCTO_CACHE_HOST}:/" "${YOCTO_CACHE_DIR}" -o fsc,nolock
          ls -al "${YOCTO_CACHE_DIR}"/$(whoami)

      # TODO: pre-install on self-hosted-runners
      # https://github.com/bloomreach/s4cmd
      - name: Install s4cmd
        run: |
          pip install s4cmd
          s4cmd --help

      - name: Build
        id: build
        env:
          HELPER_IMAGE_REPO: ghcr.io/balena-os/balena-yocto-scripts
        run: |
          ./balena-yocto-scripts/build/balena-build.sh \
            -d "${MACHINE}" \
            -t "${{ secrets.BALENA_API_KEY }}" \
            -s "${YOCTO_CACHE_DIR}/$(whoami)" \
            -g "${BARYS_ARGUMENTS_VAR}"

          if grep -R "ERROR: " build/tmp/log/*; then
            exit 1
          fi

          # if ! grep -R "Build for ${MACHINE} succeeded" build/tmp/log/*; then
          #   exit 1
          # fi

          du -cksh shared/yocto-cache/$(whoami)/*

      # TODO: pre-install on self-hosted-runners
      - name: Install zip package
        run: |
          sudo apt-get update
          sudo apt-get install -y zip

      - name: Export prepare artifacts deploy path to env
        env: 
          DEVICE_TYPE_SLUG: ${{ steps.balena-lib.outputs.device_slug }}
          VERSION: ${{ steps.balena-lib.outputs.os_version }}
        run: | 
          echo "DEPLOY_PATH=${{ runner.temp }}/deploy/${DEVICE_TYPE_SLUG}/${VERSION}" >> $GITHUB_ENV

      # TODO: prepare artifacts manually to replace balena_deploy_artifacts
      - name: Prepare artifacts
        run: |
          # DEBUG: check deploy path
          echo "DEPLOY_PATH = ${DEPLOY_PATH}"

          source "${automation_dir}/include/balena-deploy.inc"
          balena_deploy_artifacts "${{ inputs.machine }}" "${DEPLOY_PATH}" false

          # create links required for s3 prepare.ts
          # mkdir -p "${DEPLOY_PATH}/${{ steps.balena-lib.outputs.device_slug }}"

          # symlinks don't seem to work in the volume we mount to the helper image
          #ln -sf ../.. "${DEPLOY_PATH}/${{ steps.balena-lib.outputs.device_slug }}/${{ steps.balena-lib.outputs.os_version }}"
          
          find "${DEPLOY_PATH}" -exec ls -lh {} \;

      # TODO: bundle artifacts separately for convience
      # https://github.com/actions/upload-artifact
      - name: Upload artifacts
        uses: actions/upload-artifact@26f96dfa697d77e81fd5907df203aa23a56210a8 # v4.3.0
        with:
          name: build-artifacts
          if-no-files-found: error
          retention-days: 3
          # compression-level: 1
          path: |
            ${{ env.DEPLOY_PATH }}/*.*
            ${{ env.DEPLOY_PATH }}/VERSION*
            ${{ env.DEPLOY_PATH }}/image/balena{,-flasher}.img

      ##############################
      # S3 Deploy
      ##############################

      # login required to pull private balena/balena-img image
      # https://github.com/docker/login-action
      - name: Login to Docker Hub
        uses: docker/login-action@343f7c4344506bcbf9b4de18042ae17996df046d # v3.0.0
        if: inputs.deploy-s3 == true
        with:
          registry: docker.io
          username: ${{ secrets.DOCKERHUB_USER }}
          password: ${{ secrets.DOCKERHUB_TOKEN }}

      - name: Prepare files for S3
        if: inputs.deploy-s3 == true && steps.balena-lib.outputs.deploy_artifact != 'docker-image'
        env:
          HELPER_IMAGE: balena/balena-img:6.20.26
          # This path is different from DEPLOY_PATH due to the structure the prepare.ts expects: "/host/image/${device_slug}/${version}/..."
          PREPARE_DEPLOY_PATH: ${{ runner.temp }}/deploy
        run: |
          docker run --rm \
            -e BASE_DIR=/host/images \
            -v "${PREPARE_DEPLOY_PATH}:/host/images" \
            ${HELPER_IMAGE} /usr/src/app/node_modules/.bin/ts-node /usr/src/app/scripts/prepare.ts

          find "${PREPARE_DEPLOY_PATH}" -exec ls -lh {} \;

      - name: Set S3 ACL (private)
        id: s3-acl-private
        if: inputs.deploy-s3 == true && steps.balena-lib.outputs.is_private != 'false'
        run: echo "string=private" >> $GITHUB_OUTPUT

      - name: Set S3 ACL (public-read)
        id: s3-acl-public
        if: inputs.deploy-s3 == true && steps.balena-lib.outputs.is_private == 'false'
        run: echo "string=public-read" >> $GITHUB_OUTPUT

      - name: Set S3 destination directory
        id: s3-images-dir
        if: inputs.deploy-s3 == true && inputs.deploy-esr != true
        run: echo "string=images/${{ steps.balena-lib.outputs.device_slug }}" >> $GITHUB_OUTPUT

      - name: Set S3 destination directory (ESR)
        id: s3-esr-images-dir
        if: inputs.deploy-s3 == true && inputs.deploy-esr == true
        run: echo "string=esr-images/${{ steps.balena-lib.outputs.device_slug }}" >> $GITHUB_OUTPUT

      # # TODO: pre-install on self-hosted-runners
      # # https://github.com/s3-actions/s3cmd
      # - name: Set up s3cmd cli tool
      #   if: inputs.deploy-s3 == true && steps.balena-lib.outputs.deploy_artifact != 'docker-image'
      #   uses: s3-actions/s3cmd@v1.5.0
      #   with:
      #     provider: aws # default is linode
      #     region: ${{ vars.AWS_REGION || vars.S3_REGION }}
      #     access_key: ${{ secrets.AWS_ACCESS_KEY_ID || secrets.S3_SECRET_KEY }}
      #     secret_key: ${{ secrets.AWS_SECRET_ACCESS_KEY || secrets.S3_ACCESS_KEY }}
     
      # https://github.com/aws-actions/configure-aws-credentials
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@e3dd6a429d7300a6a4c196c26e071d42e0343502 # v4.0.2
        with:
          role-to-assume: ${{ inputs.aws_iam_role }}
          role-session-name: github-${{ github.job }}-${{ github.run_id }}-${{ github.run_attempt }}
          aws-region: ${{ inputs.aws_region }}
          # https://github.com/orgs/community/discussions/26636#discussioncomment-3252664
          mask-aws-account-id: false

      #"If no keys are provided, but an IAM role is associated with the EC2 instance, it will be used transparently".
      - name: Deploy to S3
        if: inputs.deploy-s3 == true && steps.balena-lib.outputs.deploy_artifact != 'docker-image'
        env:
          S3_CMD: "s4cmd --API-ServerSideEncryption=AES256"
          S3_SYNC_OPTS: "--dry-run --recursive --API-ACL=${{ steps.s3-acl-private.outputs.string || steps.s3-acl-public.outputs.string }}"
          S3_URL: "s3://${{ env.S3_BUCKET }}/${{ steps.s3-images-dir.outputs.string || steps.s3-esr-images-dir.outputs.string }}"
          SLUG: ${{ steps.balena-lib.outputs.device_slug }}
          VERSION: ${{ steps.balena-lib.outputs.os_version }}
          SOURCE_DIR: ${{ runner.temp }}/deploy
        run: |
          if [ -n "$($S3_CMD ls ${S3_URL}/${SLUG}/${VERSION}/)" ] && [ -z "$($S3_CMD ls ${S3_URL}/${SLUG}/${VERSION}/IGNORE)" ]; then
            echo "::warning::Deployment already exists at ${S3_URL}/${VERSION}"
            exit 0
          fi

          echo "${VERSION}" > "${SOURCE_DIR}/${SLUG}/latest"
          touch "${SOURCE_DIR}/${SLUG}/${VERSION}/IGNORE"

          $S3_CMD del -rf "${S3_URL}/${SLUG}/${VERSION}"
          $S3_CMD put "${SOURCE_DIR}/${SLUG}/${VERSION}/IGNORE" "${S3_URL}/${SLUG}/${VERSION}/"
          $S3_CMD ${S3_SYNC_OPTS} dsync "${SOURCE_DIR}/${SLUG}/${VERSION}/" "${S3_URL}/${SLUG}/${VERSION}/"
          $S3_CMD put "${SOURCE_DIR}/${SLUG}/latest" "${S3_URL}/${SLUG}/" --API-ACL=public-read -f
          $S3_CMD del "${S3_URL}/${SLUG}/${VERSION}/IGNORE"

      # # https://github.com/jakejarvis/s3-sync-action
      # - uses: jakejarvis/s3-sync-action@v0.5.1
      #   if: inputs.deploy-s3 == true && steps.balena-lib.outputs.deploy_artifact != 'docker-image'
      #   with:
      #     args: --follow-symlinks --sse=AES256 --acl=${{ steps.s3-acl-private.outputs.string || steps.s3-acl-public.outputs.string }}
      #   env:
      #     AWS_REGION: ${{ vars.AWS_REGION || vars.S3_REGION }}
      #     AWS_S3_BUCKET: ${{ vars.AWS_S3_BUCKET || vars.S3_BUCKET }}
      #     AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID || secrets.S3_SECRET_KEY}}
      #     AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY || secrets.S3_ACCESS_KEY }}
      #     SOURCE_DIR: ${{ runner.temp }}/deploy/image
      #     DEST_DIR: ${{ steps.s3-images-dir.outputs.string || steps.s3-esr-images-dir.outputs.string }}

      # # https://github.com/keithweaver/aws-s3-github-action
      # - uses: keithweaver/aws-s3-github-action@v1.0.0
      #   if: inputs.deploy-s3 == true && steps.balena-lib.outputs.deploy_artifact != 'docker-image'
      #   with:
      #     command: put
      #     source: ${{ runner.temp }}/deploy/image/${{ steps.balena-lib.outputs.device_slug }}/latest
      #     destination: s3://${{ vars.AWS_S3_BUCKET || vars.S3_BUCKET }}/${{ steps.s3-images-dir.outputs.string || steps.s3-esr-images-dir.outputs.string }}/
      #     aws_access_key_id: ${{ secrets.AWS_SECRET_ACCESS_KEY || secrets.S3_SECRET_KEY}}
      #     aws_secret_access_key: ${{ secrets.AWS_SECRET_ACCESS_KEY || secrets.S3_ACCESS_KEY }}
      #     aws_region: ${{ vars.AWS_REGION || vars.S3_REGION }}

     
      ##############################
      # hostapp Deploy
      ##############################

      - name: Set SECURE_BOOT_FEATURE_FLAG
        if: inputs.deploy-hostapp == true
        run: |
          if [ -n "${{ inputs.sign-image }}" = "true" ]; then
            echo "SECURE_BOOT_FEATURE_FLAG=yes" >> $GITHUB_ENV
          else
            echo "SECURE_BOOT_FEATURE_FLAG=no" >> $GITHUB_ENV
          fi

      - name: Pull helper image
        id: hostapp-helper-image
        if: inputs.deploy-hostapp == true
        env:
          HELPER_IMAGE_REPO: ghcr.io/balena-os/balena-yocto-scripts
          YOCTO_SCRIPTS_VERSION: ${{ steps.balena-lib.outputs.yocto_scripts_version }}
          YOCTO_SCRIPTS_REF: ${{ steps.balena-lib.outputs.yocto_scripts_ref }}
          HELPER_IMAGE_VARIANT: balena-push-env
        run: |
          image_tag="${HELPER_IMAGE_REPO}:${YOCTO_SCRIPTS_VERSION}-${HELPER_IMAGE_VARIANT}"
          if ! docker pull "${image_tag}"; then
            image_tag="${HELPER_IMAGE_REPO}:${YOCTO_SCRIPTS_REF}-${HELPER_IMAGE_VARIANT}"
            docker pull "${image_tag}"
          fi

          image_id="$(docker images --format "{{.ID}}" "${image_tag}")"
          echo "id=${image_id}" >> $GITHUB_OUTPUT

      # TODO: replace this with balena-io/deploy-to-balena-action when it supports deploy-only
      # https://github.com/balena-io/deploy-to-balena-action/issues/286
      - name: Deploy to balena
        if: inputs.deploy-hostapp == true
        env:
          BALENAOS_ACCOUNT: ${{ vars.HOSTAPP_ORG || 'balena_os' }}
          SLUG: "${{ steps.balena-lib.outputs.device_slug }}"
          APPNAME: "${{ steps.balena-lib.outputs.device_slug }}"
          BALENAOS_TOKEN: "${{ secrets.BALENA_API_KEY }}"
          META_BALENA_VERSION: "${{ steps.balena-lib.outputs.meta_balena_version }}"
          RELEASE_VERSION: "${{ steps.balena-lib.outputs.os_version }}"
          BOOTABLE: 1
          DEPLOY: yes
          FINAL: yes
          ESR: "${{ inputs.deploy-esr }}"
          balenaCloudEmail:
          balenaCloudPassword:
          HOSTAPP_PATH: ${{ runner.temp }}/deploy/balena-image.docker
        run: |
          docker run --rm -t \
            --privileged \
            -e APPNAME \
            -e API_ENV \
            -e BALENAOS_TOKEN \
            -e BALENAOS_ACCOUNT \
            -e META_BALENA_VERSION \
            -e RELEASE_VERSION \
            -e MACHINE \
            -e VERBOSE \
            -e BOOTABLE \
            -e DEPLOY \
            -e FINAL \
            -e ESR \
            -e SECURE_BOOT_FEATURE_FLAG \
            -e balenaCloudEmail \
            -e balenaCloudPassword \
            -v "$(readlink --canonicalize "${HOSTAPP_PATH}")":/host/appimage.docker \
            -v "${WORKSPACE}":/work \
            -v "${WORKSPACE}":/deploy \
            "${{ steps.hostapp-helper-image.outputs.id }}" /balena-deploy-block.sh

      ##############################
      # AMI Deploy
      ##############################

      - name: Set AMI arch
        id: ami-arch
        if: inputs.deploy-ami == true
        run: |
          if [ "${dt_arch}" = "amd64" ]; then
            echo "string=x86_64" >> $GITHUB_OUTPUT
          elif [ "${dt_arch}" = "aarch64" ]; then
            echo "string=arm64" >> $GITHUB_OUTPUT
          fi

      # AMI name format: balenaOS(-installer?)(-secureboot?)-VERSION-DEVICE_TYPE
      - name: Set AMI name
        id: ami-name
        if: inputs.deploy-ami == true
        run: |
          if [ "${{ inputs.sign-image }}" = "true" ]; then
            echo "string=balenaOS-secureboot-${VERSION}-${MACHINE}" >> $GITHUB_OUTPUT
          else
            echo "string=balenaOS-${VERSION}-${MACHINE}" >> $GITHUB_OUTPUT
          fi

      - name: Pull helper image
        id: ami-helper-image
        if: inputs.deploy-ami == true
        env:
          HELPER_IMAGE_REPO: ghcr.io/balena-os/balena-yocto-scripts
          YOCTO_SCRIPTS_VERSION: ${{ steps.balena-lib.outputs.yocto_scripts_version }}
          YOCTO_SCRIPTS_REF: ${{ steps.balena-lib.outputs.yocto_scripts_ref }}
          HELPER_IMAGE_VARIANT: yocto-build-env
        run: |
          image_tag="${HELPER_IMAGE_REPO}:${YOCTO_SCRIPTS_VERSION}-${HELPER_IMAGE_VARIANT}"
          if ! docker pull "${image_tag}"; then
            image_tag="${HELPER_IMAGE_REPO}:${YOCTO_SCRIPTS_REF}-${HELPER_IMAGE_VARIANT}"
            docker pull "${image_tag}"
          fi

          image_id="$(docker images --format "{{.ID}}" "${image_tag}")"
          echo "id=${image_id}" >> $GITHUB_OUTPUT

      - name: Deploy AMI
        if: inputs.deploy-ami == true
        env:
          AWS_DEFAULT_REGION: "${{ env.S3_REGION }}"
          AWS_SESSION_TOKEN: "" # only required if MFA is enabled
          AWS_SUBNET_ID: ${{ vars.AWS_SUBNET || 'subnet-02d18a08ea4058574' }}
          AWS_SECURITY_GROUP_ID: ${{ vars.AWS_SECURITY_GROUP || 'sg-057937f4d89d9d51c' }}
          BALENACLI_TOKEN: ${{ secrets.BALENA_API_KEY }}
          HOSTOS_VERSION: "${{ steps.balena-lib.outputs.os_version }}"
          AMI_NAME: "${{ steps.ami-name.outputs.string }}"
          AMI_ARCHITECTURE: "${{ steps.ami-arch.outputs.string }}"
          AMI_SECUREBOOT: "${{ inputs.sign-image }}"
          BALENA_PRELOAD_APP: "balena_os/cloud-config-${{ steps.ami-arch.outputs.string }}"
          BALENA_PRELOAD_COMMIT: current
          IMAGE: ${{ runner.temp }}/deploy/image/balena.img
        run: |
          docker run --rm -t \
            --privileged \
            --network host \
            -v "${WORKSPACE}:${WORKSPACE}" \
            -v /var/run/docker.sock:/var/run/docker.sock \
            -e VERBOSE \
            -e AWS_ACCESS_KEY_ID \
            -e AWS_SECRET_ACCESS_KEY \
            -e AWS_DEFAULT_REGION \
            -e AWS_SESSION_TOKEN \
            -e AMI_NAME \
            -e AMI_ARCHITECTURE \
            -e AMI_SECUREBOOT \
            -e S3_BUCKET \
            -e BALENA_PRELOAD_APP \
            -e BALENARC_BALENA_URL \
            -e BALENACLI_TOKEN \
            -e BALENA_PRELOAD_COMMIT \
            -e IMAGE \
            -e MACHINE \
            -e HOSTOS_VERSION \
            -e AWS_SUBNET_ID \
            -e AWS_SECURITY_GROUP_ID \
            -w "${WORKSPACE}" \
            "${{ steps.ami-helper-image.outputs.id }}" /balena-generate-ami.sh

